# Sign Language Detection System

## Team Members

| Name | Roll No |
|------|---------|
| Kodali Naga Sreeja | 2410030076 |
| Bijju Adithi Yadav | 2410030228 |
| Likitha Thumma | 2410030229 |
| H. Esha Manogna | 2410030232 |
| Malreddy Manogna | 2410030430 |

---

## üìå Overview

The **Sign Language Detection System** is a real-time application that interprets hand gestures into corresponding letters or words. It uses a webcam for live detection and employs machine learning models to recognize American Sign Language (ASL) gestures accurately. The system is designed to assist communication for people with hearing impairments.

---

## üéØ Purpose

- Facilitate communication for individuals with hearing or speech difficulties.  
- Demonstrate concepts of **computer vision, machine learning, and GUI integration**.  
- Provide an **interactive learning tool** for ASL.  

---

## ‚öôÔ∏è How It Works

1. User opens the application ‚Üí webcam activates.  
2. Hand gestures are detected in real-time.  
3. The machine learning model classifies the gesture ‚Üí displays the corresponding letter or word on the GUI.  
4. Users can also record sequences to form sentences.  

---

## ‚úÖ Key Features

- Real-time hand gesture detection.  
- User-friendly **GUI interface** with live webcam feed.  
- Supports **alphabet and basic word recognition** in ASL.  
- Lightweight and runs offline (no internet needed).  
- Visual feedback shows **detected gesture and predicted output**.  

---

## ‚ö†Ô∏è Limitations

- Works best under good lighting conditions.  
- Only supports **ASL alphabets and limited words**.  
- Detection may vary with **hand orientation, background, or camera quality**.  
- Requires a **compatible webcam** for live detection.  

---

## üöÄ Future Scope

- Extend to **full ASL vocabulary** including sentences and phrases.  
- Implement **mobile app integration**.  
- Add **voice output** for detected gestures.  
- Improve **accuracy with advanced deep learning models** and multiple camera angles.  
